# python main.py --config-path="dataset_configs/arabic/youtube/" --config-name="config_whisper.yaml"
processors_to_run: "1:"

split: train # specify dataset type (clean_train, clean_test, ...)
dataset_name: masc_dev
dataset_dir: /home/lgrigoryan/prog/asr_commonvoice_finetuning/NeMo-speech-data-processor/workdir/wer/datasets/${dataset_name}
workspace_dir: /home/lgrigoryan/prog/asr_commonvoice_finetuning/NeMo-speech-data-processor/workdir/whisper/${dataset_name}

processors:
  - _target_: sdp.processors.ASRWhisper # pip install -U openai-whisper
    pretrained_model: "large-v2"
    output_text_key: text
    output_lang_key: lid
    input_manifest_file: ${dataset_dir}/manifest_absolute.json
    output_manifest_file: ${workspace_dir}/manifest-large-v2.json

  - _target_: sdp.processors.ASRTransformers #pip install accelerate transformers
    pretrained_model: "distil-whisper/distil-large-v2" #"openai/whisper-large-v3"
    batch_size: 16
    output_text_key: pred_text
    output_manifest_file: ${workspace_dir}/manifest_result.json

  - _target_: sdp.processors.GetWER
    reference_text_field: text
    hypothesis_text_field: pred_text
    output_metric_field: wer
    output_manifest_file: ${workspace_dir}/${dataset_name}/manifest5.json


